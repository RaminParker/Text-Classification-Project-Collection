{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text classification: 20newsgroups",
      "provenance": [],
      "authorship_tag": "ABX9TyPcES4rm3B9l1I9sNGVKd2z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaminParker/Text-Classification-with-Python/blob/master/Text_classification_20newsgroups.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4jcsOn0yWii",
        "colab_type": "text"
      },
      "source": [
        "# Text classification: 20newsgroups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1Blkk4jaxZ4",
        "colab_type": "text"
      },
      "source": [
        "This notebook is a summary for me and it is based on the following article (written by Javed Shaikh): [Machine Learning, NLP: Text Classification using scikit-learn, python and NLTK.](https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5xUo06faYfB",
        "colab_type": "text"
      },
      "source": [
        "# Loading the data set\n",
        "\n",
        "The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elz7Oxva4Ox_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kCeKQRmZx8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB464PwYaVuH",
        "colab_type": "code",
        "outputId": "4adade18-7ad6-470a-8d9f-52d7e26b1679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "twenty_train.target_names #prints all the categories"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eQRzfLCemaQ",
        "colab_type": "text"
      },
      "source": [
        "Check how the data looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtv1sgTlerq9",
        "colab_type": "code",
        "outputId": "c2027ac0-caef-481a-80be-e2efc2c8524e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "print(twenty_train.data[0][:80])\n",
        "print(twenty_train.data[1][:80])\n",
        "print(twenty_train.data[2][:80])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Pos\n",
            "From: guykuo@carson.u.washington.edu (Guy Kuo)\n",
            "Subject: SI Clock Poll - Final Ca\n",
            "From: twillis@ec.ecn.purdue.edu (Thomas E Willis)\n",
            "Subject: PB questions...\n",
            "Organ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqviNKImrGsS",
        "colab_type": "text"
      },
      "source": [
        "The test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tdIpfkTrISy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGzJCDhfrLub",
        "colab_type": "code",
        "outputId": "d5bab0dd-0fe5-48fc-f8e5-b528aca7aa21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "print(twenty_test.data[0][:80])\n",
        "print(twenty_test.data[1][:80])\n",
        "print(twenty_test.data[2][:80])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. GANDLER)\n",
            "Subject: Need info on 88-\n",
            "From: Rick Miller <rick@ee.uwm.edu>\n",
            "Subject: X-Face?\n",
            "Organization: Just me.\n",
            "Line\n",
            "From: mathew <mathew@mantis.co.uk>\n",
            "Subject: Re: STRONG & weak Atheism\n",
            "Organizati\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CohRzOHGfYQd",
        "colab_type": "text"
      },
      "source": [
        "#  Extracting features from text files\n",
        "\n",
        "We use a bag of words model. Briefly, we segment each text file into words, and count # of times each word occurs in each document and finally assign each word an integer id. Each unique word in our dictionary will correspond to a feature (descriptive feature).\n",
        "\n",
        "[What is a TF-IDF Matrix (video)](https://youtu.be/G1bof7UL9RU?t=52)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3o3A8KfvC7X",
        "colab_type": "text"
      },
      "source": [
        "## Transform Data: Word Count - CountVectorizer\n",
        "\n",
        "To understand what CountVectorizer does, look at [this very simple example](https://youtu.be/0kPRaYSgblM?t=555)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOb666xOf9tD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG56FMmjcFW7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(twenty_train.data) #learning the vocabulary dictionary "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cB7OP2YgSlg",
        "colab_type": "code",
        "outputId": "8b99f976-0be7-48ff-8708-3e555465470a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train_counts.shape # --> Document-Term matrix. [n_samples, n_features]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb6eYK5dvLdR",
        "colab_type": "text"
      },
      "source": [
        "## Term Frequency Inverse Document Frequency (TF-IDF)\n",
        "\n",
        "**Term Frequency:** This summarizes how often a given word appears within a document\n",
        "\n",
        "**Inverse Document Frequency:** This downscales words that appear a lot across documents\n",
        "\n",
        "[Simple example](https://youtu.be/0kPRaYSgblM?t=755)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjMTYk3dk0vW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "More specific: \n",
        "\n",
        "**TF:**  #count(word) / #Total words, in each document.\n",
        "\n",
        "**TF-IDF:** Finally, we can even reduce the weightage of more common words like (the, is, an etc.) which occurs in all document. This is called as TF-IDF: Term Frequency times inverse document frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TpB6Mh6lbOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0AguO-eld9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-yu5QIMgUDN",
        "colab_type": "code",
        "outputId": "60a218af-5d86-4d6e-b359-2c19614be9b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train_tfidf.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4FdtTKAnoFY",
        "colab_type": "text"
      },
      "source": [
        " # Running ML algorithms\n",
        "\n",
        "There are various algorithms which can be used for text classification. We will start with the most simplest one ‘Naive Bayes (NB)’.\n",
        "\n",
        "(Note: there are many variants of NB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ob2aSHcljEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-J0enjSoKt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training Naive Bayes (NB) classifier on training data.\n",
        "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aY7zE7XqDFr",
        "colab_type": "text"
      },
      "source": [
        "# Building a pipeline \n",
        "\n",
        "We can write less code and do all of the above, by building a pipeline as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYhwWYshoRdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yk-DYwWqOEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The names ‘vect’ , ‘tfidf’ and ‘clf’ are arbitrary but will be used later.\n",
        "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())]) # build pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVPnh2ecqUJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_clf = text_clf.fit(twenty_train.data, twenty_train.target) # Training Naive Bayes (NB) classifier on training data."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVsMn1gIqxcB",
        "colab_type": "text"
      },
      "source": [
        "# Performance of NB Classifier\n",
        "\n",
        "Now we will test the performance of the NB classifier on test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKrJJ6noqbtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yD-7hb6q7tQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twenty_test = fetch_20newsgroups(subset='test', shuffle=True) # load the test data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc0RPmLZrT_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted = text_clf.predict(twenty_test.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hYCTnVnrXs_",
        "colab_type": "code",
        "outputId": "fdfa9c1d-b453-4c6b-c8c8-f968ba000109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.mean(predicted == twenty_test.target) # accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7738980350504514"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB6vXRoOsaUP",
        "colab_type": "text"
      },
      "source": [
        "# Support Vector Machines (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L2YBp8GsicR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ONbyQBrrbKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training Support Vector Machines - SVM and calculating its performance\n",
        "text_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
        "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, max_iter=5, random_state=42))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qyYnxIRswuP",
        "colab_type": "code",
        "outputId": "e5506f45-4df3-45c0-933e-fbb25bde5669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "text_clf_svm = text_clf_svm.fit(twenty_train.data, twenty_train.target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvkp2HZHszgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_svm = text_clf_svm.predict(twenty_test.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl388vX-s1jP",
        "colab_type": "code",
        "outputId": "73375734-0304-452f-b0f4-3c61ca0c6019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.mean(predicted_svm == twenty_test.target) # accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8248805098247477"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Azv-IyyQtRFz",
        "colab_type": "text"
      },
      "source": [
        "# Grid Search\n",
        "\n",
        "Fine tune parameters!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GysKbGSjtZVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEReTc3zt0wY",
        "colab_type": "text"
      },
      "source": [
        "Here, we are creating a list of parameters for which we would like to do performance tuning. \n",
        "All the parameters name start with the classifier name (remember the arbitrary name we gave).\n",
        "\n",
        "E.g. vect__ngram_range; here we are telling to use unigram and bigrams and choose the one which is optimal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXuawh0Ts2-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False), 'clf__alpha': (1e-2, 1e-3)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nngIOmrUt_Io",
        "colab_type": "text"
      },
      "source": [
        "Next, we create an instance of the grid search by passing the classifier, parameters and n_jobs=-1 which tells to use multiple cores from user machine.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtW8zeH3tPY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqXbNvFwuL0v",
        "colab_type": "code",
        "outputId": "9996d384-9f5d-4f75-f52e-6db1fd81ac76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "# This might take few minutes to run depending on the machine configuration.\n",
        "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Le7F_XPpudiA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Lastly, to see the best mean score and the params, run the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCyr-HnduQmu",
        "colab_type": "code",
        "outputId": "8bc80994-bd23-4c1c-ff32-74e37978eb3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "gs_clf.best_score_ # accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9157684864695698"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbmWRtwIvlJy",
        "colab_type": "code",
        "outputId": "e10f9f31-b497-4ebc-a105-9ca385b7d2da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "gs_clf.best_params_ # optimal parameters"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPp7FQUXwByj",
        "colab_type": "text"
      },
      "source": [
        "## Grid search for SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jsf3vohswL96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define parameter range\n",
        "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False),'clf-svm__alpha': (1e-2, 1e-3)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO4U5YS5wPQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an instance of the grid search\n",
        "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Morh9-3GxAOX",
        "colab_type": "code",
        "outputId": "c064b524-1970-45ac-c21e-887a5a057daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "# This might take few minutes to run depending on the machine configuration.\n",
        "gs_clf_svm = gs_clf_svm.fit(twenty_train.data, twenty_train.target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftNtJWo1wQ2d",
        "colab_type": "code",
        "outputId": "0ec81eca-7f29-440b-8c80-d582afaada11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "gs_clf_svm.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9047198366213406"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq4sIXL4wSuC",
        "colab_type": "code",
        "outputId": "dac022a6-aa71-4116-9053-df36c4728b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "gs_clf_svm.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf-svm__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEhUxLmOyHGy",
        "colab_type": "text"
      },
      "source": [
        "Useful tips: see last steps in the [article](https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwxCYvZrwUnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}